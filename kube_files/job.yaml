apiVersion: v1
kind: Pod
metadata:
  # Name of the pod. This is the name to use in any interaction with kubectl
  name: train
spec:
  securityContext:
    # You need to specify your user ID here. You can get this by running "id -u"
    runAsUser: 1224
  volumes:
  # The following 3 entries are the NFS mounts available to you. You do not need to
  # modify them. They are for your home folder, and the shared tools and datasets
  # folders.
  - name: home
    persistentVolumeClaim:
      claimName: home
  - name: tools
    persistentVolumeClaim:
      claimName: tools
#  - name: data1
#    persistentVolumeClaim:
#      claimName: data1
#  - name: data2
#    persistentVolumeClaim:
#      claimName: data2
#  - name: data3
#    persistentVolumeClaim:
#      claimName: data3
#  - name: scratch1
#    persistentVolumeClaim:
#      claimName: scratch1
  - name: scratch6
    persistentVolumeClaim:
      claimName: scratch6
  # The following 3 entries make the Nvidia drivers available. You do not need to
  # modify them.
  #- hostPath:
  #    path: /usr/lib/nvidia-driver/bin
  #  name: nvbin
  #- hostPath:
  #    path: /usr/lib/nvidia-driver
  #  name: nvlib
  - hostPath:
     path: /usr/lib/
    name: usrlib
  - hostPath:
      path: /usr/bin
    name: bin
  - hostPath:
      path: /lib
    name: lib
 # You can specify a label indicating a specific model of GPU here when you need it.
  # Leave it commented when learning how to use the cluster.
  nodeName: shannon
   # This part specifies the Docker container in which your code will run.
  containers:
  - name: local-image-container
   # image: local-image:latest
    imagePullPolicy: IfNotPresent
  #- name: py # The container also has a name but it ususally doesn't matter
    # This is the Docker image on which your container is based. Leave it unchanged.
    image: ubuntu:16.04
    # This is the command which is run once the container is created. Point it to
    # your code. It is best to encapsulate your commands in a shell script and
    # call that script like below.
    # 
    # Note that all paths have to be according to the filesystem inside the container.
    command: ["/bin/bash", "/scratch/scratch6/jonathanvevance/projects/ddp_thesis_substruct/kube_files/run.sh"]
    # This section specifies the resources you ask for.
    resources:
      # For the purposes of using the cluster, the "requests" section should be the
      # same as the "limits" section except for the line for GPU
     limits:
        nvidia.com/gpu: 1        
        #alpha.kubernetes.io/nvidia-gpu: 1 # Number of GPUs
        # RAM can be specified in either MiB (1024x1024 bytes) (ex. "500Mi")
        # or GiB (ex. "4Gi")
        memory: "48Gi"
        cpu: "1" # Number of CPU cores
     requests:
        memory: "48Gi"
        cpu: "1"
    # Here, you can specify where you want the above directories to be mounted
    # within the container. It is recommended to use this configuration as
    # it mirrors what is present on the master machine.
    volumeMounts:
    # Entry for your home folder. Make sure to replace <username> with your
    # username.
    - mountPath: /storage/home
      name: home
    # Entry for the other folders mentioned above.
    - mountPath: /tools
      name: tools
#    - mountPath: /datasets/data1
#      name: data1
#    - mountPath: /datasets/data2
#      name: data2
#    - mountPath: /datasets/data3
#      name: data3
#    - mountPath: /scratch/scratch1
#      name: scratch1
    - mountPath: /scratch/scratch6
      name: scratch6
#    - mountPath: /usr/local/nvidia/bin
#      name: nvbin
#    - mountPath: /usr/local/nvidia/lib
#      name: nvlib
    - mountPath: /usr/lib/
      name: usrlib
    - mountPath: /usr/bin/
      name: bin
    - mountPath: /lib
      name: lib
  restartPolicy: Never
